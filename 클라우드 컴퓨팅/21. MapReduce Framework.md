# Mapper 클래스

- org.apache.hadoop.mapreduce.Mapper 클래스이다.
- 모든 맵퍼 클래스의 base 클래스이다.
- Mapper 클래스에 속한 메소드들은:
    - `protected void **setup**(Mapper.Context context)`
    - `protected void **cleanup**(Mapper.Context context)`
    - `void **run**(Mapper.Context context)`
    - `protected void **map**(KEYIN key, VALUEIN value, Mapper.Context context)` 

    `Context`는 Mapper와 Reducer가 Hadoop system과 interact하게 해준다.

- `void **run**(Mapper.Context context)`


    - Mapper 클래스의 전체 구동 함수에 해당하며, 전문가가 아니라면 이 메소드를 override 할 일은 거의 없다.
    - MapReduce 프레임워크에서 Mapper 클래스의 객체를 만들고 주어진 입력 파일을 레코드의 집합으로 만든 다음, 각 레코드들을 Mapper 클래스 객체의 run 메소드의 입력으로 넣어 준다.
- `protected void **setup**(Mapper.Context context)`
    - Map 태스크가 시작될 때 단 한 번 실행된다.
    - map 메소드에서 필요한 리소스를 할당하거나 map 에서 필요한 선행 작업을 여기에서 할 수 있다.
    - 예) 파일을 미리 오픈해 놓는다, 등.
    - Mapper 클래스에서는 아무 일도 하지 않는 것으로 되어 있으며, 이를 override 해서 쓰면 된다.
- `protected void cleanup(Mapper.Context context)`
    - map 함수의 호출이 완료되면, 즉, 모든 입력 레코드의 처리가 완료되면 마지막으로 한 번 호출된다.
    - setup 에서 할당된 리소스가 있다면 여기에서 해제하면 된다.
    - Mapper 클래스에서 이 메소드는 아무 일도 하지 않는 것으로 되어 있어서, 이를 override 해서 쓰면 된다.

응용에 따라 `map( )` 이 key, value 쌍을 출력하도록 하지 않고, `setup ( )` 에서 리소스를 할당하고, `map( )`에서 그 리소스를 사용하여 정보를 쌓아 놓은 다음에, `cleanup( )` 에서 총체적인 처리를 하도록 할 수도 있다.

## 맵 입력

16p안 봐도 됨

- `TextInputFormat` : 기본적인 입력 포맷
    - WordCount 에서도 이 입력 포맷을 사용함
    - 텍스트 라인 하나가 하나의 레코드가 된다.
    - key : 해당 라인의 파일 오프셋 (파일 처음부터의 위치) ( 타입 : LongWritable )
    - value : 해당 라인 전체 ( 타입 : Text )
- 많이 사용되는 다른 입력 포맷
- `KeyValueTextInputFormat` : 한 줄에 key 와 value 가 함께 있는 포맷
- `SequenceFileInputFormat` : Hadoop 고유의 파일 포맷, 바이너리 파일, 내부 작업시 사용하는 포맷
- 만일 `TextInputFormat` 이 아닌 다른 입력 포맷을 사용하려면 `job.setInputFormatClass( )` 메소드를 호출해서 변경함
    - main( ) `job.setInputFormatClass(KeyValueTextInputFormat.class)`
- 맵 태스크가 읽어들일 입력 파일들의 위치 지정
    - `FileInputFormat.addInputPath(job, new Path(args[0]));`
    - 입력 파일들이 여러 폴더에 분산되어 저장되어 있다면 (동일 포맷의 경우), 이 메소드를 그 개수만큼 호출하거나, addInputPaths 를 호출해서 다수의 입력 파일 경로를 한 번에 지정할 수도 있음
    - `SequenceFileInputFormat` 의 경우
    `FileInputFormat` 클래스의 `addInputPath` 로 지정하는 것이 아니라, 다른 방법을 사용함

## 맵 출력

- 맵의 출력 레코드들의 타입 (key와 value 타입들)이 전체 하둡 job 의 출력 타입들
(결국 리듀스의 출력 타입들)과 다르다면 job 클래스의 다음 두 메소드를 호출하여 프레임워크에 알려 주어야 한다.
- `setMapOutputKeyClass, setMapOutputValueClass`
 (ex) `job.setMapOutputKeyClass(Text.class)`,  `job.setMapOutputValueClass(IntWritable.class)`
- WordCount 에서는 맵의 출력 타입들과 리듀스의 출력 타입들이 일치했기에 이 메소드들을 호출하지 않았음
- 만약 맵 출력만 필요하고 리듀스는 아예 필요없다면 리듀스 태스크의 수를 0으로 지정할 수 있다.
- 이 경우 정해 놓은 하둡 job의 출력 디렉토리에 맵의 출력물들이 바로 저장된다.
- 출력 파일들의 이름은 리듀스한 경우 part-r- 이고 리듀스 없는 경우는 part-m- 으로 시작한다.
- part-m 파일의 수는 맵 태스크의 수와 동일하다

## Identity Mapper

- 맵이 필요 없는 경우에 사용한다.
- 주어진 입력 레코드 (key, value)를 그대로 출력 레코드로 내보낸다.
- 모든 맵 클래스의 base 클래스가 되는 Mapper 가 사실 Identity 맵으로 구현되어 있다.

- identity map 이 필요한 경우, 별도로 맵 클래스를 구현할 필요 없이 base 클래스인 Mapper 클래스를 그대로 사용
- `job.setMapperClass(Mapper.class)`

## MapReduce 프로그램에서 사용되는 변수 타입들

- 어떤 타입이 맵이나 리듀스에서 key 로 사용되기 위해서는 `WritableComparable` 이라는 인터페이스를 구현해야 하고, value 로 사용되기 위해서는 `Writable` 이란 인터페이스를 구현해야 한다.
- `WritableComparable` 은 Writable 인터페이스를 포함한다.
- Serialization (직렬화)
: 어떤 객체나 자료구조가 네트워크를 타고 전송되거나 디스크에 저장될 수 있도록 변환해 주는 과정 (Marshalling 이라고도 부른다)
- Deserialization (역직렬화)
: 직렬화되어 전송된 데이터를 다시 원래 자료구조로 복구하는 과정

### Writable 인터페이스

- Writable 인터페이스
    - 직렬화/역직렬화(serialization / deserialization)을 구현하는데 사용되는 메소드들을 가지고 있다.
    - 하둡의 특성상 키/밸류 레코드가 디스크에 저장되거나 네트워크를 타고 전달되어야 하기 때문에 이런 인터페이스가 필요하다.
    - 하둡은 RPC (remote procedure call) 을 이용해서 클러스터 내의 노드들 간에 통신을 한다. 이 때에도 함수 인자나 리턴 값들을 네트워크를 타고 송수신해야 하며, 이 때에도 Writable 인터페이스를 사용한다.
- Writable 인터페이스가 가지고 있는 메소드
- `write` : 해당 객체가 직렬화될 때 호출되는 메소드
- `readFields` : 해당 객체가 역직렬화될 때 호출되는 메소드

### WritableComparable 인터페이스

- Writable 에서 제공되는 메소드들을 포함한다.
- 그리고 객체들간의 비교를 가능하게 해 주는 자바의 `Comparable` 인터페이스가 추가된 인터페이스이다.
- 하둡에서 맵과 리듀스에서 사용되는 key들은 소팅이 가능해야 하므로 이러한 인터페이스가 필요하다.
- Comparable 인터페이스에는 **`compareTo`** 라는 메소드 하나가 존재하며 이는 지금 객체와 인자로 들어온 객체를 비교하여 둘 사이의 순서를 정해 주는 역할을 한다.

## 입력 포맷 클래스

- 입력 파일들을 어떻게 해석하는가를 결정
- 입력 파일을 어떻게 레코드들로 나누는가?
- 각 레코드에서 key와 value를 어떻게 나눌지 결정한다
- 입력 포맷 클래스 종류
1. TextInputFormat
2. KeyValueTextInputFormat
3. SequenceFileInputFormat
4. MultipleInputs
5. CombineFileInputFormat, NLineInputFormat 도 있음

### TextInputFormat

- FileInputFormat 클래스를 상속
- 텍스트 파일, .gz 으로 압축된 것도 처리 가능
- 파일의 line 1개가 하나의 입력 레코드에 해당
- 레코드
- key : line의 (파일 선두로부터의) 파일 오프셋, type : `LongWritable`
- value : line 전체 스트링, type : `Text`

### KeyValueTextInputFormat

- 기본적으로 `TextInputFormat` 과 같다. 단,
- 파일의 line 1개
- key와 value로 구성되어 있다고 본다.
- key와 value 는 tab과 같은 분리자로 구분
- 분리자 설정 (tab 아닌 경우)
job 환경 설정 (Configuration) 인스턴스의 set 메소드를 호출하여 `key.value.separator.in.input.line` 프로퍼티의 값을 다른 분리자로 설정
- key 와 value 타입은 모두 `Text` 이다.

## 맵 태스크 수의 결정 방식

- 입력 파일의 수와 맵 테스크의 개수
    - 맵 태스크의 수는 입력 파일의 개수보다 작을 수는 없다.
    - 작은 크기의 입력 파일이 너무 많으면 맵 태스크의 수도 많아져서 실행 효율이 떨어진다.
- 입력 파일의 크기
    - 입력 파일이 크면 데이터 블록들로 나뉜다 (default 128MB~256MB).
    - 맵 태스크는 블록마다 1개씩 할당된다.
- 압축되는 등 분할이 어려운 경우는
    - 블록 수에 무관하게 전체 파일에 맵 태스크가 1개 지정된다.
    - `InputFormat` 클래스에 `isSplitable` 메소드를 사용해 블록 단위로 나눌 수 있는 것인지 없는 것인지 지정해 줄 수 있다.

## 컴바이너

- 미니 리듀서 (mini reducer) 또는 로컬 리듀서 (local reducer) 라고 부른다.
- 맵 태스크의 출력에 리듀스 코드를 먼저 적용하여 리듀스로 데이터가 이동하기 전에
데이터의 크기와 통신량을 줄인다.
- 모든 job에 컴바이너를 적용할 수 있을까? No
    - 교환 법칙과 결합 법칙이 만족되는 job에 컴바이너를 적용할 수 있다.
    - 예제 : 합, 최솟값, 최댓값 등을 구할 때 가능
    - 부적합한 경우 : 평균값 구하기 등

사실 컴바이너는 한 번이 아니라 수시로 실행될 수 있다. 대용량 데이터를 다룰 때 block이 하나만 있는 것이 아니기 때문에, block 마다 map task가 실행되고, 컴바이너가 map task에서 출력이 나올 때마다 실행될 수 있다. 

추가적으로, map task가 진행이 되면서 결과들이 나오면 컴바이너를 돌고, 컴바이너를 통해 데이터가 어느 정도 나오면 reduce로 연결이되고, 파이프라인 처럼 데이터가 계속해 reduce쪽으로 흘러 들어간다.

## 셔플링과 소팅

framework의 핵심. map task의 출력을 reduce task에게 전달해주는 부분

병렬 분산 처리가 효율적으로 이루어지도록 함.

- 리듀스 태스크의 개수 (default는 1개)
    - job 클래스의 `numReduceTasks` 메소드로 지정함
- 파티셔너 ( Partitioner )
    - 맵 태스크의 결과 레코드의 key 값을 해싱을 해서 그 해싱 값을 리듀스 태스크의 수로 나누어 그 레코드가 어떤 리듀스 태스크로 갈지 정해주는 클래스
- 기본으로 사용되는 클래스이름 : `HashPartitioner`
- 자신만의 파티셔너를 구현한다면
    - job 클래스의 `setPartitionerClass` 메소드로 지정해 주면 됨

## 맵 출력 버퍼링

- 맵에서 출력된 레코드 (key, value) 들은 파티셔너 클래스를 통해 파티션 번호가 배정된다.
- 이들은 메모리 버퍼에 쓰여졌다가 버퍼가 어느 정도 다 차면 그 때 디스크 파일로 저장된다.
- 맵 태스크가 종료될 때까지 이 과정을 반복하는데, 종료 시에는 디스크로 저장되었던 파일들을 모두 모아서 하나의 파일로 합병한다.
- 그런 다음에 리듀스 태스크들이 각기 자신에게 해당하는 파티션의 데이터를 읽어가게 된다.
- 맵 태스크가 초기화될 때 (기본) 100MB 크기의 버퍼가 메모리에 생긴다.
- 맵에서 출력 레코드가 생길 때마다 파티셔너 클래스를 통해 그 레코드의 파티션 번호가 정해진다. (파티션 번호, 키, 밸류) 정보를 메모리 버퍼에 쓴다.
- 버퍼가 80% 차면, 버퍼의 내용을 디스크에 쓴다. 파일 이름은 spill 임.
spill 이 만들어질 때 파티션 번호 순서로 레코드들이 정렬된다.
- 맵 출력이 더 없을 때까지 이 과정을 반복한다.
- spill 의 개수가 너무 많아지지 않도록 spill 파일의 최댓값을 가지고 있다.
- spill 의 수가 이 수를 넘어가면 디스크 기반 merge sort 를 한다.
- 맵 출력이 끝나면, 모든 spill 파일들과 메모리 버퍼의 남은 것들을 모두 하나의 디스크 파일로 merge sort 한다.
- 컴바이너는 spill 이 발생할 때, 또는 spill 간의 합병이 될 때 실행된다. 즉 여러 번 실행된다.

## Shuffling & Sorting

- M 개의 맵 태스크와 N 개의 리듀스 태스크가 있다고 하자.
- 맵 태스크가 종료된 후, 각 리듀스 태스크는 M 개의 맵 태스크들과 각각 연결을 맺고 자신에 해당하는 파티션 데이터를 읽어 간다. 이를 Shuffling 이라고 한다.
- MxN 개의 네트워크 커넥션이 맺어지고, 데이터가 네트워크를 통해 복사 된다.
- 이 때 전송되는 데이터의 양이 크다면 네트워크의 대역폭이 병목 지점이 된다.
- 리듀스 태스크는 모든 맵 태스크에서 데이터를 가져온 후 이들을 하나로 합병한다.
- 합병된 데이터에 대해 key를 기준으로 sorting을 한다.
- sorting이 끝나면 레코드들을 전체적으로 스캔하면서, 레코드들을 그룹핑한다.
즉, 같은 키를 갖는 레코드들을 하나로 묶어서 하나의 리듀스 입력 레코드를 만든다.

## 리듀스 클래스

- 모든 리듀스 클래스의 base 클래스
    - `Reducer (org.apache.hadoop.mapreduce.Reducer)`
    - run, setup, reduce, cleanup 이 있음

## 리듀스 태스크

- 리듀스 태스크 개수는 프레임워크에서 정하지 않고 사용자가 준 값을 그대로 사용한다.
- Job 클래스의 setNumReduceTasks 메소드를 호출하여 그 숫자를 결정하면 된다. (호출 없으면, default = 1)
- 맵 태스크의 출력 레코드들이 shuffling & sorting 을 거쳐 리듀스 태스크의 입력이 된다.
- 리듀스의 출력 레코드는 HDFS 상에 저장된다.
- 출력 포맷을 정할 수 있으며 기본적으로는 `TextOutputFormat` 이다.
- key 와 value 는 리듀스에서 출력한 그대로 저장되며 둘 사이에는 TAB 문자가 놓이는 것이 default이다.
- 다른 출력 포맷
- `SequenceFileOutputFormat`
- 출력 파일들의 위치 지정
- `FileOutputFormat` 클래스의 `setOutputPath` 메소드

## Identity Reducer

- identity reducer 클래스: 입력 레코드들을 그대로 출력해 준다.
- 모든 리듀스 클래스의 베이스 클래스인 Reducer 클래스는 identity reducer 로 구현되어 있다.

- 즉 맵 태스크가 출력한 것을 그대로 출력하는 셈이지만, 셔플링과 소팅 때문에 맵 태스크들에서의 원래 출력과 순서가 달라진다.
- `job.setReducerClass(Reducer.class);` 를 사용하면 된다.
- identity reducer 의 사용 예 : 이미지 변환, 문서 분류기 등에 사용
- 단순한 작업을 여러 서버에서 동시에 실행하고 싶을 때 사용된다.

## 리듀스 기타

- reduce 메소드의 인자인 value 리스트(Iterable)는 한 번만 스캔 가능. 입력 레코드들이 메모리에 모두 저장되기에는 너무 클 수 있기 때문
- 리듀스 태스크 수를 0으로 하는 것과 identity 리듀서를 쓰는 것과의 차이
    - 리듀스 태스크의 수를 0으로 하는 경우 (파일 이름은 part-m- 으로 시작)
    - 맵 태스크들의 출력이 그대로 job 전체의 최종 출력이 된다.
    - 최종 출력물의 개수는 맵 태스크의 개수와 같다.
    - identity reducer 를 쓰는 경우 (파일 이름은 part-r-로 시작)
    - 레코드 순서가 달라진다
    - 최종 출력물의 파일 수는 리듀스 태스크의 개수 (job.setNumReduceTasks 메소드로 지정)

## 출력 포맷

`TextOutputFormat`
- 텍스트 파일 생성, 출력 레코드가 하나의 라인, 키와 밸류 사이에 TAB 문자가 있다.
- setCompressOutput, seOutputCompressorClass 를 사용하여 압축 가능 `SequenceFileOutputFormat`
- 시퀀스 파일 포맷으로 출력, 여러 하둡 job을 이어서 실행할 경우 사용해야 하는 출력 포맷
- SequenceFileOutputFormat 클래스의 setOutputCompressionType 메소드를 통해 압축 방식 지정

- 압축 모드 (BLOCK) : 블록 내의 레코드들을 함께 압축, (NONE) : 압축하지 않음, (RECORD) : 레코드 별로 압축

`MapFileOutputFormat`
- 출력을 맵 파일 형태로 만들어주는 출력 포맷, 이런 파일은 SequenceFileInputFormat 으로 읽을 수 있음
- 맵 출력이 임시 저장되는 파일들은 사실 맵 파일 형태로 유지된다.
