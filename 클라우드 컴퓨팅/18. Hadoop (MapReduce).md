# Apache Hadoop

Apache: 오픈SW 서비스를 제공, 개발을 지원하는 재단. Hadoop도 Open source

## What Is Apache Hadoop?

### Hadoop 프로젝트

안정적이고 확장가능한 분산 컴퓨팅을 하기 위한 오픈 소스 소프트웨어 개발

reliable, scalable, distributed computing

### Hadoop 소프트웨어 라이브러리는 프레임워크

클러스터 상에 분산 저장되어 있는 대용량 데이터 셋을 대상으로 분산처리를 가능하게 함

간단한 프로그래밍 모델 사용

### 단일 서버에서도, 수천 대 컴퓨터로 구성된 클러스터상에서도 실행 가능

클러스터 내의 각 컴퓨터에서 로컬 컴퓨팅과 스토리지 기능 제공

### 고가용성 보장

고품질 하드웨어를 사용하는 것이 전혀 아님

응용 레이어에서 자체적으로 오류 감지하고 해결하도록 라이브러리가 설계되어 있음

## Big Data

대용량 데이터. structured or unstructured

- 빅데이터의 특징
    - Volume 엄청난 크기
    - Velocity 엄청나게 빠른 속도로 생성이 된다.
    - Variety

⇒ Hadoop은 이러한 big data의 저장과 처리에 적합한 framework이다.

## Birth and growth of Hadoop

### Google에서 시작

- 세상의 모든 데이터를 대상으로 검색 엔진을 제공하려는 목적
- 기존의 저장 체계와 파일 체계로는 수집한 대량의 데이터를 대상으로 검색용 인덱스를 만들기 어려움
- 대량의 웹사이트 데이터를 저장하고 처리할 수 있는 미들웨어(분산 처리 기술)를 자체적으로 개발했음.
    - 2003, The Google File System (데이터 저장에 관한 분산 파일 시스템)
    - 2004, MapReduce: Simplified Data Processing on Large Clusters (data 분산 처리 프레임워크)

    ⇒ 이 두 논문의 내용을 오픈 소스로 구현한 것이 **Hadoop**

## Hadoop

- 데이터 저장: HDFS(Hadoop Distributed File System)에 저장
- 데이터 처리: Hadoop MapReduce 사용

## Hadoop Ecosystem (하둡 생태계)


Hadoop 프로젝트: 안정적이고 확장 가능한 분산 컴퓨팅을 하기 위한 오픈 소스 소프트웨어 개발

- Hadoop 구조
    - **HDFS**에 데이터 저장
    - **YARN**으로 리소스(CPU, Memory, Disk, Network) 관리
    - **MapReduce**로 데이터 처리

## Hadoop: 병렬분산 처리 시스템


대용량 데이터를 대상으로 어떤 job을 수행하려고 한다. 순차 처리 하려면 시간/공간 복잡도가 너무 높아 병렬/분산 처리를 하려고 한다.

병렬/분산 처리를 하기 위해 데이터 집합을 블록 단위로 분할하여 분산시키고, 각 블록을 대상으로 수행할 task도 지정해 준다.

각 블록에 대한 task의 병렬 실행이 완료되면 계산 결과를 취합하여 최종 결과를 낸다.

## Hadoop MapReduce 프레임워크에 대한 이해

- MapReduce는 대규모 데이터 집합을 처리하기 위한 프로그래밍 모델
- 병렬처리를 위해 job를 여러 개의 task들로 나누어 실행한다.

## Hadoop Architecture


5대의 컴퓨터에 하둡을 설치. 한 대는 master 역할, 나머지는 slave 역할.

→ Hadoop architecture은 master-slave 구조이다.

- master의 역할

: task와 data를 slave에 할당하고 리소스를 관리한다. (Resource Manager, Name node 설치)

- slave의 역할

: 실제 데이터를 저장 (metadata는 master에), 가진 데이터를 대상으로 '처리' (Node Manager, DataNode 설치)

Node Manager: resource를 관리

DataNode: data를 관리

Map & Reduce: task 처리 - 자신이 가지고 있는 데이터를 대상으로 '처리'

### HDFS

HDFS : Hadoop Distributed File System

- Hadoop 의 data storage에 해당
- 데이터는 block 단위로 분할되어 각 slave node에 분산 저장
- 데이터 관리를 위해 master node 에서는 NameNode daemon 이 실행되고,
- 각 slave node 에서는 DataNode daemon이 실행된다.
- NameNode : file system namespace 관리 (파일 이름 관리)
- data 에 대한 metadata 저장
- file opening, closing, renaming files or directories
- mapping blocks to DataNodes
- DataNode :
- 클라이언트가 요구하는 read, write 를 file system 상에서 처리한다.
- NameNode 의 요구 처리 (block의 생성, 삭제, 복제, 등)
- 기존의 파일 시스템:
리눅스의 ext4, XFS 등은 한 대의 컴퓨터 노드 상에서 파일을 관리하기 위한 것
- 분산 파일 시스템 HDFS:
**여러 대의 컴퓨터 노드에서 규모가 큰 하나의 파일 시스템을 제공**한다.
    - **HDFS**: 각 slave node (DataNode)에 있는 ext4 같은 로컬 파일 시스템 상에서 만들어지는 '오버레이 파일 시스템' (각 slave Node의 DataNode에 폴더를 만들어 합치면 하나의 파일이 되도록 관리)
    - **HDFS 상에 배치된 파일**은 128MB, 256MB 크기의 블록으로 분할되어 각 slave node에 저장되지만, 각 블록 데이터는 ext4같은 로컬 파일 시스템의 **파일**로 취급된다.

    ```bash
    $ hadoop fs -put srcfile destfile
    ```

    local system의 srcfile이 여러 개의 block으로 나뉘어져 destfile로 hadoop 시스템에 저장되는 명령어

    ```bash
    $ hadoop fs -mkdir testdir
    ```

    hadoop에서 폴더 생성

    - **HDFS의 특징**
        - **투과성** 클라이언트는 데이터 관리 방식을 모른다.
        - **확장성** DataNode 추가 가능 (저장공간이 부족하다면 slave node를 추가 가능)
        - **신뢰성** 각 블록 다중 기록을 통한 데이터 손실 방지(reliable), NameNode는 High Availability 서버로 구성
    - **데이터 접근 패턴**
    기록(저장)은 1회, 그 이후 읽기만 허용, 데이터 변경 불가, 랜덤 읽기 금지(파일을 처음부터 읽어야 함)

## HDFS: Data Replication


- file은 여러 개의 block 들로 분할되어 저장된다. (Default size는 128MB, 256MB)
지정된 block 크기로 분할, 마지막 block 은 작을수도 있음
- fault tolerance 를 위해 block 들은 여러 copy로 저장
- file 생성시 (또는 이후)에 replica 개수 지정 (지정하지 않으면 Default로 3 copies)
- file 생성 후 읽기 연산만 허용
- NameNode 의 역할
    - block replication 관련 모든 것을 결정하고 관리
    - DataNode 로부터 주기적으로 heartbeat 와 blockreport 를 받음
    - heartbeat : DataNode 가 제 기능하고 있는가 체크
    - blockreport : DataNode 에 저장된 block 정보 확인

## YARN (Yet Another Resource Negotiator)

리소스 관리자. (Resource Manager, Node Manager)

- Resource
    - CPU, memory, disk, network 등을 뜻함
- YARN 에서는 resource management(master) 와 job scheduling/monitoring (slave) 기능의 분리
- Resource Manager (daemon)
    - 실행중인 응용 사이에서 리소스 중재
- Node Manager (daemon)
    - 컨테이너가 사용하는 리소스 모니터링
    - 그런 내용을 Resource Manager 에게 보고
- Application Master
    - Resource Manager 와 리소스 협상
    - NodeManager 와 협업하여 job 실행, 모니터링

## MapReduce 처리 진행 과정

프로그램을 작성해 실행시키면 Map과 Reduce task가 실행. 경우에 따라 하나만 실행 되기도 함.


Split: HDFS 파일시스템의 block을 말함

프로그램이 실행 되면 먼저 Map task들이 실행, Split으로 부터 데이터를 하나씩 읽으며 중간 결과를 생성,

중간 결과(intermediate)는 Map task가 실행이 되는 컴퓨터 노드의 local disk에 일단 저장이 됨.

Map task의 실행이 끝나면 Map task에서 생성된 intermediate result들이 Reduce task들에게 입력으로 이동.

intermediate result에는 목적지(Reduce task)가 있음. 목적지에 따라 이동해 Reduce에게 입력으로 이동

mapper node로부터 reducer node로 데이터가 이동하는 것을 shuffling이라고 함.

Reduce task마다 모아진 intermediate data들이 있으며 이것이 합병. 합병된 것이 input. 

Reduce들은 이 합병된 input을 대상으로 최종 작업을 하고, 최종 결과는 HDFS에 저장


어떤 부분을 framework가 해 주는지, 어떤 부분을 프로그래머가 해야 하는지 구분을 해야 함.

### MapReduce 처리 과정

- Map 처리

입력 데이터는 HDFS 상의 블록 단위로 분할 저장된 파일들이다 (split)

MapReduce 프레임워크는 각 Map 태스크를 slave node 들에게 할당한다.

각 Map 태스크는 동일한 노드에 저장되어 있는 블록을 처리한다.

각 Map 태스크

- 입력 데이터(128MB, 256MB 크기의 블록 정도)로부터 key-value 쌍을 1개씩 꺼내어
사용자가 정의한 Map 처리를 수행하고, 처리 결과도 key-value 형태로 출력한다.
(처리 결과 = intermediate result)
- (key, value) = (상품a, 5)
- Shuffle 처리

Map 처리가 끝나면 MapReduce 프레임워크가 Map 처리 후 생성된 (intermediate result) 데이터를 정렬 (sort)해서 같은 키를 가진 데이터를 같은 노드로 모아준다. ( 전표 분류 예제에서 : 동일 상품에 대한 전표 묶음 )

이 때 slave node 들 사이에 네트워크를 통한 전송이 발생한다.

Shuffle 처리는 MapReduce 가 자동으로 수행하므로, 사용자가 별도로 처리해 줄 것은 없지만,
이 때 네트워크를 통한 데이터 전송이 발생하는 것을 인지해야 한다.

전송 데이터 양이 크면, Shuffle 처리에 시간이 많이 든다.

- Reduce 처리

Shuffle 을 통해 key 별로 모아진 데이터에 대해 Reduce 처리를 한다.
(전표 분류 예제에서 : 동일 상품에 대해 판매 수량을 합산하여 상품별로 판매 수를 계산한다.)
