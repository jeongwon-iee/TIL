# OpenMP 소개

- OpenMP 는 공유 메모리 환경에서 사용하는 “directive-based” API 이다.
directive: 컴파일러에게 주는 명령어
- OpenMP 의 “MP” 는 “multiprocessing”을 의미한다.
- 프로그래머가 “병렬화 가능한 코드 블록”을 지정해 놓으면, 그것을 참고로 하여 (실제) 병렬화는 컴파일러와 런타임 시스템이 결정하고 처리한다.
- OpenMP의 설계 목적
프로그래머가 순차 프로그램을 점진적으로 (incrementally) 병렬화해 갈 수 있도록 하자

# Threads 생성과 실행, Hello 프로그램

## OpenMP 프로그램의 실행 과정


프로그래머는 병렬 처리가 가능한 block마다 컴파일러에게 directive를 넣어준다.

master thread가 실행하고 있다가, 병렬 처리 가능한 code block을 만들면 thread들을 추가적으로 생성해 병렬 처리를 해주고, 병렬 처리가 끝나면 다시 thread를 소멸 시킨다.

## Hello Program

```c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>

void Hello(void); /* Thread function */

int main(int argc, char * argv[]) {
	/* Get number of threads from command line */
	int thread_count = strtol(argv[1], NULL, 10);

#pragma omp parallel num_threads(thread_count) // 밑의 함수를 병렬로 실행해라.
	Hello(); // thread가 실행할 함수

	return 0;
}

void Hello(void) {
	int my_rank=omp_get_thread_name(); // thread 번호
	int thread_count=omp_get_num_threads(); // thread 개수
	printf("Hello from thread %d of %d\n", my_rank, thread_count);
}
```

```bash
$ cc hello.c -o hello -fopenmp
$ ./hello
```

## OpenMP pragmas

### #pragma omp parallel

기본적인 parallel directive

이 directive 아래에 있는 코드 블록을 몇 개의 thread로 실행할 것인가 하는 것은 runtime system이 결정한다.

### clause: directive 옆에 추가 되는 글

- num_threads clause
코드 블록을 실행할 쓰레드 개수를 프로그래머가 명시할 때 쓰인다.
`# pragma omp parallel **num_threads ( thread_count )**`
- 생성하고자 하는 쓰레드 개수를 프로그래머가 프로그램에 명시한다고 해도,
시스템은 생성할 수 있는 만큼만 쓰레드 개수를 생성한다. (시스템이 정한 최대 쓰레드 개수가 있음)
- OpenMP 표준은 thread_count 개수만큼 쓰레드를 생성해 주지 않을 수도 있다.
- 요즘 OpenMP 는 일반적으로 수백, 수천개의 쓰레드는 생성할 수 있도록 해 준다.
- 이 숫자를 넘지 않는다면, 프로그래머가 원하는 수 만큼의 쓰레드를 생성해 준다.
- OpenMP 에서 병렬 코드 블록을 실행하는 쓰레드 관련 용어
- team : 원래 쓰레드와 새로 생성된 쓰레드를 함께 지칭한다.
- master : 원래 쓰레드
- slaves : 새로 생성된 쓰레드들
- ***다음 경우에 implicit barrier 가 있음***
- 쓰레드 하나가 코드 블록의 실행을 마쳤다고 해도, 다른 모든 쓰레드들이 그 코드 블록의 실행을 마칠 때까지 대기한다.
- 모든 쓰레드가 코드 블록의 실행을 끝냈을 때, slave threads 들이 종료되고, master 만 남아서 프로그램의 실행을 계속 진행한다.

# Trapezoidal Rules 사용 함수 적분 계산

## 적분 문제: 순차 프로그램

## 적분 문제: 병렬 프로그램

### Critical Secti


```c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>

void Trap(double a, double b, int n, double * global_result_p);
double f(double x) { return 2*x};

int main(int argc, char * argv[]) {
	/* 공유 변수들 */
	double global_result = 0.0; 
	double a, b; // left and right endpoints
	int n;
	int thread_count;

	thread_count = strtol(argv[1], NULL, 10);
	printf("Enter a, b, and n\n", &a, &b, &n);

#pragma omp parallel num_threads(thread_count)
	Trap(a, b, n, &global_result);
	
	printf("With n = %d trapezoids, out estimate = %.14e\n", n, global result);
	return 0;
}

void Trap(double a, double b, int n, double * global_result_p) {
	/* 모두 thread private한 변수들 */
	double h, x, my_result;
	double local_a, local_b;
	int i, local_n;
	int my_rank = omp_get_thread_num(); // thread 번호
	int thread_count = omp_get_num_threads(); // thread 개수

	h=(b-a)/n;
	local_n=n/thread_count;
	local_a=a+my_rank*local_n*h;
	local_b=local_a+local_n*h;
	my_result=(f(local_a)+f(local_b))/2.0;
	
	for(i=1; i<=local_n-1; i++) {
		x=local_a+i*h;
		my_result+=f(x);
	}

	my_result=my_result*h;

#pragma omp critical
	*global_result_p += my_result; // 오직 하나의 thread만 실행
}
```

## Scope of Variables

변수들의 공유 범위. 어떤 변수가 공유 변수이고 thread private한 변수인지

- 변수들의 scope
    - 순차 프로그램 : 그 변수들을 프로그램의 어떤 부분에서 사용할 수 있는가 그 범위를 말한다. (전역 변수 인가, 지역 변수 인가)
    - OpenMP : “parallel block 안에 있는” 변수의 scope 이란 그 변수에 어떤 쓰레드들이 접근할 수 있는가를 나타낸다
    - team 안의 모든 쓰레드가 접근할 수 있는 변수들 (shared scope)
    - 쓰레드 1개만이 접근/사용할 수 있는 변수들 (private scope)
    - parallel block 을 실행하기 전에 선언된 변수들의 default scope 은 shared 이다.

### another version of Trap()

- 앞의 프로그램에서 사용한 Trap 함수의 구조

    `void Trap(double a, double b, int n, double * global_result_p)`
    thread는 자신이 맡은 구역의 적분값을 계산 후 공유 변수에 직접 대입

- Local_trap()

    ```c
    	global_result=0.0;
    #pragma omp parallel num_threads(thread_count)
    	{
    #pragma omp critical
    		global_result += Local_trap(a, b, n);
    	}
    ```

    모든 thread가 순차 처리를 하게 되어 병렬 처리의 의미가 없음

- parallel block 안에서 private 변수를 만들고, Local_trap()을 critical section 밖으로

    ```c
    	global_result=0.0;
    #pragma omp parallel num_threads(thread_count)
    	{
    		double my_result = 0.0; // private
    		my_result += Local_trap(a, b, n);
    #pragma omp critical
    		global_result += my_result; // reduction
    	}
    ```

    local 계산이 완료된 후에 critical section을 둔다.

## Reduction Clause

- parallel directive에 reduction clause를 추가할 수 있다.


    ```c
    	global_result=0.0;
    #pragma omp parallel num_threads(thread_count) ₩
    		**reduction (+: global_result)**
    		global_result += Local_trap(a, b, n);
    ```

- Local_trap()을 계산해 값을 private 변수에 모은 후 critical section에서 global_result에 더하는 것과 같은 결과
- reduction clause 에 포함되어 있는 변수는 공유 변수이다. (`global_result`)
- reduction clause 의 실행
- 공유 변수가 포함되어 있는 명령문을 쓰레드가 실행할 때는 그 쓰레드가 혼자 사용할 수 있는 private 변수가 생성되고, 그 변수에서 reduction operation 이 진행된다.
- parallel block 의 실행이 다 끝나고 나면, 그 private 변수에 저장되어 있는 값을 공유 변수에 누적시켜 준다.
- 쓰레드의 private 변수는 (자동으로) 실행하려는 reduction operator의 identity value 로 초기화가 되어 있다.
예를 들어 덧셈을 하려면 0으로, 곱셈을 하려면 1로 초기화 되어 있다.

## Parallel For Directive

for 문장의 iteration을 병렬적으로 처리하기

- parallel for directive 바로 밑에는 for 문장이 있어야 한다.
- 그 for 문장을 실행하기 위해 여러 쓰레드가 생성이 되며 각 쓰레드는 for 문의 iteration 을 나누어 실행한다.

### parallel for의 실행 예제

```c
a();
#pragma omp parallel for
for(int i=0; i<10; ++i) c(i);
z();
```

- thread 0이 혼자서 a()를 실행한다.
- parallel for 를 만나면 쓰레드가 여러 개 생성되고 각 쓰레드는 for 문의 iteration 을 나누어 맡아 실행한다.
- thread 0 는 모든 쓰레드의 실행이 끝날 때까지 기다린 후, parallel for 를
실행하던 쓰레드들이 다 종료된 후에 혼자 남아서 z( ) 를 실행하게 된다.

### Parallel for Directive를 사용한 적분 계산

```c
	h=(b-a)/n;
	approx=(f(a)+f(b))/2.0;
#pragma omp parallel for num_threads(thread_count) ₩
	reduction (+: approx)
	for(i=1; i<= n-1; i++)
		approx+=f(a+i*h);
	approx=h*approx
```

• for 문장의 iteration 을 여러 쓰레드가 나누어 맡아 처리한다.
• approx는 pragma omp parallel for 위에서 선언된 변수로 공유변수이다.
• for 문의 iteration 마다 공유변수인 approx. 에 모든 쓰레드가 접근하여 덧셈을 하지 말고, reduction 으로 처리한다. 즉, 각 쓰레드가 local 변수에 합산을 다 한 후에 for 문의 실행이 끝날 때, 그 변수의 값을 공유변수인 approx 에 더하도록 한다.
• for 문의 제어 변수인 i 는 thread 에 private 변수

### Data Dependencies (fibonacci)

```c
	fibo[0]=fibo[1]=1;
#pragma omp prallel for num_threads(2)
	for(i=2; i<n; i++)
		fibo[i]=fibo[i-1]+fibo[i-2];
```

- for 문의 iteration이 순서대로 실행되는 것이 아니다.
- 컴파일러는 for문의 iteration 사이의 dependencies를 체크 해주지 않는다.

### Data Dependencies (π)

```c
	double factor=1.0;
	double sum=0.0;
#pragma omp parallel for num_threads(thread_count) ₩
	reduction(+:sum)
	for(k=0; k<n; k++) {
		sum+=factor/(2*k+1);
		**factor=-factor;**
	}
	pi_approx=4.0*sum;
```

```c
	double factor=1.0;
	double sum=0.0;
#pragma omp parallel for num_threads(thread_count) ₩
	reduction(+:sum) private(factor)
	for(k=0; k<n; k++) {
		**if(k%2==0) factor=1.0;
		else factor=-1.0;**
		sum+=factor/(2*k+1);
	}
	pi_approx=4.0*sum;
```

factor 변수는 쓰레드마다 별도로 가지고 있을 수 있도록 private scope로 지정한다.

factor 변수의 값은 iteration 마다 계산하여 정해, loop dependency를 제거한다.

### The default clause

프로그래머가 parallel block 안에서 사용하는 모든 변수들의 scope를 명시하겠다는 뜻

`**default(none)**`

default 절을 사용하면, 프로그래머는 parallel block안에서 사용하는 모든 변수들의 scope를 명시해야 한다.

```c
	double factor=1.0;
	double sum=0.0;
#pragma omp parallel for num_threads(thread_count) ₩
	default(none) reduction(+:sum) private(factor) ₩
	shared(n)
	for(k=0; k<n; k++) {
		**if(k%2==0) factor=1.0;
		else factor=-1.0;**
		sum+=factor/(2*k+1);
	}
	pi_approx=4.0*sum;
```

### Serial Odd-Even Transposition Sort

```c
for (phase=0; phase<n; phase++)
	if(phase%2 == 0)
		for(i=1; i<n; i+=2)
			if(a[i-1]>a[i]) Swap(&a[i-1], &a[i]);
	else
		for(i=1; i<n-1; i+=2)
			if(a[i]>a[i+1]) Swap(&a[i], &a[i+1]);
```

• 원소가 n 개일 때 n phase 로 진행됨
• phase 마다 모든 원소들은 인접한 원소와 쌍을 이루어 비교되고, 비교 결과 왼쪽 값이 더 크면 swap 한다.
• phase 번호가 짝수일 때, (비교시에) 모든 쌍의 왼쪽 원소의 인덱스는 짝수이고,
• phase 번호가 홀수일 때, (비교시에) 모든 쌍의 왼쪽 원소의 인덱스는 홀수이다.
• 원소 사이의 비교가 병렬적으로 진행가능한 (일종의) 버블 정렬이라고 볼 수 있음

### OpenMP Odd-Even Sort (loop dependency 제거)

```c
#pragma omp parallel num_threads(thread_count) ₩
	default(none) shared(a,n) private(i, tmp, phase)

for(phase=0; phase<n; phase++) {
	if(phase%2==0)
#   pragma omp for
		for(i=1;i<n;i+=2) {
			if(a[i-1]>a[i]) {
				tmp=a[i-1];
				a[i-1]=a[i];
				a[i]=tmp;
			}
		}
	else
#   pragma omp for
		for(i=1;i<n-1;i+=2) {
			if(a[i]>a[i+1]) {
				tmp=a[i+1];
				a[i+1]=a[i];
				a[i]=tmp;
			}
		}
}
```

parallel block을 실행하기 위해 thread_count 개수 만큼의 쓰레드를 생성해 놓는다.

pragma omp for 실행할 때는 이미 생성되어 있는 쓰레드들을 사용해서 for문의 iteration을 실행 시킨다.

## Scheduling loops

parallel for를 실행할 때, thread가 실행할 iteration을 배정해주는 다양한 방법

### Loop: Cyclic Partitioning

thread 0은 iteration 0, 1은 1, ... t는 t, 0은 t+1, ...

(default assignment: thread마다 block단위로 iteration을 배정)

⇒ default보다 빠를 때가 있다.

```c
	double sum=0.0;
#pragma omp parallel for num_threads(thread_count) ₩
	reduction(+:sum) **schedule(static, 1) //** schedule 명시
	for(k=0; k<n; k++) sum += f(k);
```

### schedule (type, chunksize)

- type의 종류
    - **static**: loop가 실행되기 전에 iteration 들이 쓰레드에 배정된다.
    - **dynamic** or **guided**: loop가 실행 되는 과정에 iteration들이 배정된다.
    - **auto**: 컴파일러나 런타임 시스템이 스케쥴을 결정한다.
    - **runtime**: runtime이 스케쥴을 결정한다
- chunksize는 양의 정수이다.
*chunk: thread에게 한 번에 배정되는 iteration 개수*

### Dynamic Schedule Type

- 인접한 iteration 들을 모아 chunksize 개수 크기의 chunk 로 나누어 놓는다.
- 각 쓰레드는 chunk 하나씩 실행을 한다. *쓰레드는 chunk 하나의 실행을 끝내고 나서, 런타임 시스템한테 next chunk 를 (dynamic) 요청한다.*
- 모든 chunk 의 실행이 끝날 때까지 이런 방식으로 진행된다.
- chunksize 가 생략된 경우에는 chunksize 를 1로 간주한다.

### Guided Schedule Type

- 각 쓰레드는 chunk를 실행한다. 실행이 끝나면 다른 chunk를 요청한다.
- *새로 받게 되는 chunk의 크기는 이전 chunk 보다 점점 작아진다.*
- chunksize 를 명시하지 않으면 chunk 의 크기는 1이 될 때까지 줄어든다.
- chunksize 를 명시하면 새 chunk 의 크기는 그 크기까지만 줄어든다. 또한 마지막 chunk 의 크기는 chunksize 보다 작을 수도 있다

⇒ Guided schedule에선 왜 chunk size를 점점 줄여나갈까?

iteration 한 번 실행하는데 드는 시간을 잘 모를 때 dynamic schedule이나 guided schedule을 사용하는데, chunk size를 처음부터 작게 해서 배정한다면 동적으로 배정을 많이 해야 하니, 처음부터 크게 배정하여 chunk요청 횟수를 줄이며 thread간의 load balancing을 하기 위해서

## Locks

lock을 사용하여 critical section을 보호할 수 있다.

```c
# pragma omp critical
	Enqueue(queue, my_rank, mesg);
```

```c
omp set_lock(&lock);
Enqueue(queue, my_rank, mesg);
omp unset_lock(&lock);
```

## The Atomic Directive

critical directive와 달리 보호할 문장이 단 1개인 경우에는 atomic directive를 사용한다.

```c
# pragma omp atomic
	간단한 대입 문장
```

# Matrix vector multiplication

```c
# pragma omp parallel for num_threads(thread_count) ₩
		default(none) private(i,j) shared(A,x,y,m,n)
	for(i=0; i<m; i++) {
		y[i]=0.0;
		for(j=0; j<n; j++)
			y[i] += A[i][j]*x[j];
	}
```
