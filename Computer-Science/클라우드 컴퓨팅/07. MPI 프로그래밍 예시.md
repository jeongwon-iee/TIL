# MPI 프로그램 구조

- 커뮤니케이터
- 태그

    ⇒ 2 byte (0~32767) short

- 메시지 전송 방법 (send, receive)

## 커뮤니케이터 (Communicator)

서로 통신할 수 있는 프로세스들의 scope를 정해줌

⇒ 같은 커뮤니케이터 안에 속해있는 프로세스 끼리만 통신 가능.

- `MPI_Init()` 이 MPI 프로그램에서 실행되는 모든 프로세스들을 모아 커뮤니케이터 `MPI_COMM_WORLD` 를 생성
- 이 커뮤니케이터 안에 속해있는 모든 프로세스들에게 프로세스 번호를 할당

    (0 ~ p-1). 이 번호를 rank 라고 함.

    → 각 프로세스는 자신의 번호를 어떻게 아는가?

    `MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);`

- 다른 커뮤니케이터들도 만들 수 있다.

## `int MPI_Comm_rank(MPI_COMM cm, int* rank)`


새로운 커뮤니케이터를 생성하면, 그 안에서의 프로세스 번호가 새로 부여됨

→ 어떤 프로세스가 여러 커뮤니케이터에 속해있다면, 커뮤니케이터 마다 프로세스 번호를 가질 수 있음

프로세스 번호 받아오는 방법 : `MPI_Comm_rank(커뮤니케이터이름, &my_rank);`

## `int MPI_Comm_size(MPI_COMM cm, int* size)`


커뮤니케이터의 사이즈를 size 변수에 받아옴

## MPI_Send & MPI_Recv

MPI_Send: 데이터를 보내는 데 사용하는 함수

MPI_Recv: 데이터를 받는 데 사용하는 함수 (바로 실행 x. 데이터가 도착할 때까지 기다림)

- MPI_COMM_WORLD에 속한 프로세스 0과 1사이의 데이터 통신 예제

    
    태그를 붙여 프로세스 0의 **시스템 버퍼로** 데이터 전송, 

    프로세스 0은 시스템 버퍼에서 1번이 보낸 Tag=5인 데이터를 받음, status X

---

# MPI 프로그램 예제

- 다양한 예제 프로그램
- 와일드 카드 (MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_STATUS_IGNORE)
- status의 활용 (MPI_SOURCE, MPI_Get_count())

## 프로그램 1: node1 → node0 통신하는 경우


```bash
$ mpiexec -n 2 ./p.exe
```

변수 a, b, my_rank, p는 프로세스 두 개가 모두 각각 가짐

자신이 가진 프로그램을 읽으면서 각 프로세스가 실행

일반적인 MPI 프로그램엔 함수 세 개가 먼저 호출 됨

- Initialize

    `MPI_Init(NULL, NULL)`

- rank // 나는 몇 번인가

    `MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);`

- size // 현재 몇 개의 프로세스가 이 프로그램을 실행하는가

    `MPI_Comm_size(MPI_COMM_WORLD, &p);`

Recv함수는 시스템 버퍼에서 받아올 데이터가 없다면 계속 기다림

a 변수에서는 꺼내서 보내고, b 변수엔 받은 데이터를 저장

- Finalize // MPI 프로그램 종료

    `MPI_Finalize()`

## 프로그램 2: 메시지 받는 순서를 정하는 경우


프로세스 5개가 이 프로그램을 실행 (변수 n==5)

```bash
$ mpiexec -n 5 ./p.exe // 절대 경로명을 써도 됨
```

각 프로세스의 변수 a에 rank값*15가 저장됨

MPI_Send를 실행해 값을 프로세스 0에 전송

프로세스 0은 **for loop를 돌면서** 시스템 버퍼에 저장된 데이터를 Receive (네 번 실행)

어떤 순서로 프로세스0에 도착하는지는 모르지만, 메세지가 모두 시스템 버퍼에 들어와 있기 때문에 프로세스0은 source 순서대로 메시지를 받아옴

- 절대경로에 공백이 있다면 전체를 ""로 감싸줘야 함

## 프로그램 3: 순서 없이 메시지를 받는 경우


`MPI_ANY_SOURCE` 와일드카드 사용! ⇒ source에 무관하게 도착하는 대로 데이터를 읽어들임

실행시 프로세스 개수를 p로 받아 프로세스 개수만큼 for loop를 돌림

- 누가 보냈는지 어떻게 확인?

    `status.MPI_SOURCE`

데이터를 받는 대로 출력하는 모양

실행 결과는 매번 달라질 수 있음


순서에 무관하게 먼저온 데이터를 먼저 받아 속도를 향상

## 프로그램 4: 메시지를 모두 받은 후 한 번에 출력


데이터를 받는 대로 배열에 저장한 후 한 번에 출력하는 모양

`status.MPI_SOURCE` 를 이용해 source를 저장하는 배열 따로 둠

배열 이름이 포인터이기 때문에 배열 이름 `b+i` 사용

## 프로그램 5: 와일드카드 & 각 메시지의 길이 다름


자신의 rank 개수만큼 배열로 데이터를 만듦. Send를 이용해 데이터 전송

`MPI_ANY_SOURCE` `MPI_ANY_TAG` 와일드 카드 사용. 몰라도 receive 가능

⇒ 각 프로세스가 보내는 데이터 분량이 다를 수 있고, 분량을 몰라도 받은 후 파악할 수 있다.

## 프로그램 6: 메시지가 노드를 순회하는 경우


## 프로그램 7: 모든 노드가 send → receive


버퍼에 여유공간이 많을 때만 가능

---

## Message Tag

메시지를 구분할 때 사용

TAG가 필요 없을 때 쓰는 와일드카드 `MPI_ANY_TAG` 

⇒ Tag에 무관하게 데이터를 받을 수 있다.

### unsafe message passing

Tag를 사용해도 메시지 구별이 가능하지 않은 경우

```c
if (my_rank == 0) {
		send(x, 1);
		lib_call(...);
}
else {
		lib_call(...);
		recv(y, 0);
}
```

문제 상황) library 함수가 시스템 버퍼에 있는 data를 가져갈 수 있다.


⇒ 커뮤니케이터를 달리하여 해결할 수 있다!

- 통신은 같은 커뮤니케이터 안에서만 일어나며
- 커뮤니케이터는 통신의 스코프를 정하는 역할을 한다.

## MPI Solution: "Communicators"

- 커뮤니케이터는 커뮤니케이션 도메인을 정의하고, 도메인 안에 속한 프로세스들만이 서로 통신이 가능하다.
- 라이브러리의 커뮤니케이션 도메인은 프로그래머가 사용하는 커뮤니케이션과 다르다. (서로 다른 이름의 커뮤니케이터를 만들 수 있다.
- 커뮤니케이터는 point-to-point communication(send, receive) 뿐 아니라 collective MPI(broadcast: 여러 프로세스가 참여하는 통신)도 할 수 있다.
