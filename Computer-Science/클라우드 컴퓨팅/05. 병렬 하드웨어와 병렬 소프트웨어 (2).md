병렬 하드웨어에는 SIMD 시스템과 MIMD 시스템이 있고,

SIMD 시스템은 명령 하나가 제어 장치로 들어오면,  제어 장치가 명령을 순차적으로 여러 개의 ALU들에게 broadcasting

MIMD 시스템에 대해 병렬 소프트웨어 프로그래밍을 할 것.

MIMD 시스템은 독립적인 CPU들로 구성, 메모리에 따라 공유 메모리 시스템, 분산 메모리 시스템으로 나뉨

---

# 병렬 소프트웨어

MIMD 시스템을 대상으로 하는 병렬 프로그램 개발에 초점을 맞추기로 한다.

- 병렬 소프트웨어 개발을 위해 알아 두어야 할 사항

**- 공유 메모리 프로그램**


병렬 프로그램은 메모리에 실행 파일로 올라가 있을 것. CPU 중 하나가 프로그램을 실행시키면 여러 쓰레드들이 생김, 쓰레드들이 여러 CPU들에 올라가 실행

공유 메모리 모델에서는 CPU들이 프로그램 안의 변수를 공유

프로세스 하나를 실행시키면, 그 프로세스가 여러 쓰레드를 포크 (fork) 하고, 그렇게 생성된 쓰레드들이 태스크를 병렬로 수행한다.

⇒ 변수 관리가 중요

 **- 분산 메모리 프로그램**


Ethernet 같은 연결망에 연결된 DeskTop PC들의 집합, 노드마다 하나의 프로세스가 생겨, 각 프로세스들이 독립적으로 실행, 노드 간 데이터 이동 가능

여러 프로세스가 실행되고, 그들이 병렬 태스크들을 수행한다.

## SPMD 프로그래밍

Single Program, Multiple Data 

병렬 프로그램을 작성해 여러 노드 상에서 실행 시킬 것.

- 실행할 파일은 1개이다.
- 모든 프로세스( 또는 쓰레드)는 이 파일을 실행한다.
- 실행 파일에 들어있는 조건문을 통해 각 프로세스 (또는 쓰레드) 는 자신이 할 일을 찾아 수행하게 된다


프로세스들은 자신만의 ID를 가지고, 조건문에 따라 노드들에 나뉘어 각각 실행됨

⇒ 똑같은 프로그램을 여러 프로세스들이 실행하나, 각자 다른 일들을 수행

## SPMD or MPMD?

**SPMD (single program multiple data) 프로그래밍**

- 실행할 프로그램이 1개이다.

**MPMD (multiple program multiple data) 프로그래밍**

- 실행할 프로그램이 여러 개 이다.
- 일반적으로 2개이다.
    - Master 용 프로그램
    - Worker 용 프로그램
- MPMD 프로그램은 SPMD 프로그램으로 변환 가능

    
## 병렬 프로그램 작성 시 프로그래머가 할 일

병렬 프로그램을 작성할 때 프로그래머는 다음 일에 신경 써야 한다.

- 프로세스 (또는 쓰레드) 간의 **작업량 균등화 (load balancing)**

    프로세스들 사이의 워크로드를 균등하게 배분해야 한다.

    
- 프로세스 (또는 쓰레드) 간의 **동기화 (synchronization)**

    메모리 공유 시 프로세스 간 동기화가 필요

    
- 프로세스 (또는 쓰레드) 간의 **통신 (communication)**

    프로세스 간에 통신을 하나 가능한 적게

## 공유 메모리 프로그램: 쓰레드 사이의 통신

- 공유메모리 프로그램에서 변수들은 shared 또는 private 으로 선언된다.
- 공유 (shared) 변수들은 모든 쓰레드가 읽거나 쓸 수 있는 변수들이다.
- 프라이빗 (Private) 변수들은 대체로 하나의 쓰레드만이 접근할 수 있다.
- 쓰레드 사이의 통신(Communication)은 주로 공유 변수를 통해 이루어진다.

    즉, 통신은 명시적인 것이 아니라 묵시적으로 이루어지는 셈이다.

    (CPU 사이엔 연결망이 없으니까)

## 분산 메모리 시스템: 프로세스 사이의 통신

- 프로세스들은 자신만이 쓸 수 있는 private 메모리를 가지고 있다.
- 프로세스 사이의 통신에 쓸 수 있는 API 가 다수 개발되어 있지만, 주로 쓰이는 방법은 **메시지 패싱 (message-passing)**이다.


자신의 프로세스 번호를 받아 메시지를 보내고 받음. 

⇒ 분산 메모리 시스템에서 프로세스들은 ***통신함수를 통해***  데이터를 주고 받는다.

## 입력과 출력에 대한 가정

- 다수의 프로세스/쓰레드가 동시 다발적으로 입력과 출력을 하는 상황이다.

앞으로의 공부에서 가정할 사항

- 분산메모리 프로그램에서는 프로세스 0만이 *stdin* 을 엑세스한다. (프로세스 0이 master 역할)
- 공유메모리 프로그램에서는 master thread (또는 thread 0) 만이 *stdin*을 엑세스한다.
- 분산메모리나 공유메모리 프로그램에서, 모든 프로세스/쓰레드들은 *stdout* 과 *stderr*를 엑세스할 수 있다.
- 그러나 *stdout* 결과가 비결정적(indeterminate) 순서이기 때문에 (프로세스 간 출력 순서가 매번 다를 수 있음) 대부분의 경우 오직 하나의 프로세스/쓰레드 만이 stdout 에 쓰도록 프로그래밍을 한다.
- 또한 각 프로세스/쓰레드는 읽거나 쓰기를 위한 프라이빗 파일을 열 수 있지만, 여러 프로세스/쓰레드가 동일한 파일을 열 수는 없다.
- 디버그 (debug) 출력은 항상 출력을 생성하는 프로세스/쓰레드의 랭크 (rank) 또는 ID를 포함한다

⇒ 일반적으로 프로세스 하나를 정해 입출력을 한다.

---

# 병렬 프로그램의 성능 평가

성능 평가를 위한 척도

- Speedup
- Efficiency
- Maximum speedup

## Speedup & Efficiency

`**Speedup`**  병렬 프로그램이 순차 프로그램보다 몇 배나 더 빨리 실행 되는가?

= 순차 프로그램의 실행 시간과 병렬 프로그램 실행 시간의 비율

= 몇 배 더 빨라졌는가?

`**Efficiency**` 전체 시스템의 몇 % 효율을 올리는가, 활용 되었는가?


각 프로세스는 80% 밖에 성능을 내지 못 함 `0 ≤ E ≤ 1`

## Linear Speedup


: 병렬 프로그램의 speedup 이 실행에 사용한 프로세서 개수와 같을 때, 그 프로그램은 linear speedup 을 낸다고 한다. 즉, 사용한 프로세서 개수에 선형적으로 비례하여 속도가 향상된다는 뜻이다.

### 병렬 프로그램의 Speedup과 효율성에 대한 예제

- 프로세스 개수가 증가할 수록 프로그램의 speedup이 감소하는 이유는?
- 프로세스 사이의 통신 오버헤드, 동기화에서의 유휴자원 등으로 프로세스 개수가 증가함에 따라 efficiency가 감소하는 것이 일반적

### 문제 크기 변화에 따른 병렬 프로그램의 성능 향상과 효율성

- problem size가 커질수록 speedup 이 상대적으로 커지는 이유는?

    (Problem size는 프로그램이 처리할 데이터의 크기)

⇒ 통신 등에 드는 오버헤드에 비해 각 프로세스가 계산에 쓰는 시간이 상대적으로 증가하여 효율이 좋아진다.

## 오버헤드 (Overhead)

문제의 크기(처리할 데이터 크기)가 증가하면 speedup과 efficiency가 향상된다.

- 병렬 프로그램의 실행 시간:
- 순차 프로그램의 할 일 (work)을 여러 프로세스/쓰레드가 나누어서 일을 하는데 드는 시간
- Mutual exclusion 이나 통신 등에 드는 오버헤드 (p: 프로세스 개수)

    
## 최대 스피드업 (Maximum Speedup)

일반적으로 p개의 프로세서를 사용했을 때 얻을 수 있는 Speedup은 최대 p (linear speedup)

**Superlinear speedup** : Speedup이 p이상일 때

- multiprocessor system을 사용해 메모리가 늘어 속도가 느는 경우

    순차적으로 처리할 때보다 병렬로 처리할 때 속도가 훨씬 늘 수 있음

- Nondeterministic algorithm


순차 프로그램을 병렬로 실행한다면 시간을 얼마나 단축시킬 수 있는가?

- 암달의 법칙
- Gustafson의 법칙

## 암달의 법칙 (Amdahl's law)

순차 프로그램 전체가 병렬화 되지 않는다면, 사용 가능한 프로세서의 개수에 상관없이 가능한 성능 향상은 매우 제한적이다.


p → 매우 커질 때 S(p) = $1/f$ 이라서 속도 단축이 제한적이다.

but, 현실적으로 p가 매우 커질 수도 없고, p가 매우 커질 때 병렬 프로세스의 처리 시간이 0에 수렴 하지도 않음

- 순차 프로그램에서 순차적으로 실행되어야 하는 부분이 5%라고 하고, 20개의 프로세서를 사용하여 병렬화 한다고 하자.

    
## Scaled Speedup : Gustafson의 법칙

가정:
1) 병렬 프로그램의 실행 시간을 고정해 보자 (constant)
2) 순차 프로그램에서 순차적으로 실행되어야 하는 부분도 코어 개수인 p와 상관없이 고정적이다.

- 순차 프로그램에서 순차적으로 실행되어야 하는 부분이 5%라고 하고, 20개의 프로세서를 사용하여 병렬화 한다고 하자.

   
    - 병렬처리의 목적은 프로세서를 많이 사용해 시간을 단축하는 것보다 더 많은 양의 데이터를 처리하는 것이 목적이니, 순차처리를 하는 만큼의 시간동안 병렬 처리를 했을 때의 Speedup과 비교해야 한다.

        → Speedup을 19.05까지 낼 수 있다.
