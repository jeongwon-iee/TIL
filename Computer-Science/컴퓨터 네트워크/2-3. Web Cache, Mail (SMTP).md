# 지난 시간 배운 내용

`Pop Quiz`

(1) end system간에 메시지를 주고 받을 때 다양한 network 를 거쳐감 (internet), 여러 개의 network를 거쳐가는 역할을 수행하는 Layer 

⇒ NetworkLayer (End to End 경로를 routing 하는 계층)

(2) end system 에만 있는 Layer 

⇒ Application & Transport Layer

(3) process to process에 logical 한 connection을 제공 

⇒ Transport Layer (TCP, UDP)

port 번호로 host에서 executing(running)하는 process를  identify

(4) 호스트(=end system)를 찾아가는 역할 

⇒ Network Layer (IP address로 host를 identify)

3,4 계층은 OS에 올라가 있는 software

(5) 하나의 네트워크를 통과하는 역할

⇒ Link Layer (한 홉을 지나가게 함) 

Network Interface Card에 올라가 있는 software

---

# Web caches (proxy server)

: http 프로토콜을 사용하는 loss-sensitive한(TCP) 두 end system에 있는 어플리케이션이 communication 하기 위해 TCP connection을 맺은 후 두 프로세스에 전용 소켓이 생겼다. 연결을 맺은 후에도 client는 http request에 host url을 담아 보낸다. 

⇒ **연결을 맺은 후에도 client가 http msg에 host url을 또 넣어 보내는 이유**

proxy server는 client와 같은 ISP 내에 있는 경우가 많음

같은 community에 있으면 이미 한 요청을 다른 client가 보낼 가능성이 높기 때문에 client는 server와 바로 연결을 맺지 않고 같은 ISP의 proxy server와 연결

proxy는 web cache, cache hit의 경우 client에게 proxy server가 보유한 response(object)를 주고, cache miss시 proxy server는 origin server의 client가 되어 다시 connection을 맺어 받은 reponse를 client에게 전해줌

client는 server와 바로 연결을 맺지 않고 같은 ISP의 proxy server와 연결을 맺어 결론적으로 traffic이 밖으로 나가는 걸 줄여줄 수 있음

⇒ client의 http msg는 origin server(내 ISP 밖으로 나가는 external traffic, external link)로 가는 것이 아닌, 같은 ISP 안에 있는 proxy server(내 ISP 내에서의 internal traffic, internal link)로 전송

## More about Web caching

<img width="684" alt="스크린샷 2020-11-05 오후 4 11 03" src="https://user-images.githubusercontent.com/45806836/98208971-86ef3d00-1f81-11eb-9ab4-52bca42463e1.png">

- cache는 origin client에겐 server, origin server에겐 client 역할
- 주로 cache는 같은 ISP 내에 설치

### why Web caching?

- reduce response time for client request

⇒ cache hit의 경우 response time이 감소

- reduce traffic on an institution's access link

⇒ proxy server와 origin server간의 access link의 traffic 감소

(link의 traffic 감소→ external traffic delay 감소, 이동 통신망 유지 비용 감소)

- enable "poor" content providers to effectively deliver content

⇒ proxy가 가진 응답은 proxy가 처리해주어 resource가 포화한 server에게 간접적으로 도움이 된다.

- access control to external traffic, auditing

⇒ proxy 서버를 이용하면 ISP 내에서의 traffic과 외부로 나가는 traffic을 제어, 감시할 수 있다.

### caching example: access link 증설 vs proxy 구축

<img width="702" alt="스크린샷 2020-11-05 오후 4 11 50" src="https://user-images.githubusercontent.com/45806836/98209027-9e2e2a80-1f81-11eb-9c9c-0c7b46450d1d.png">

Internet router: public internet의 router(POP의 한 router)

Institutional router: institutional network의 가장 마지막 router

access link를 증설하는 것과 proxy 서버를 구축하는 것 어느 쪽이 나을까?
`parameter`

- avg object size: (response에 담긴 object) 100K bits ⇒ L (패킷 길이)
- avg request rate from browsers to origin server: 15 req/sec ⇒ a (B, 초당 queue에 얼만큼 들어오는가)

    = queueing delay에서 얘기한 avg request rate
    
    ⇒ avg response rate to browsers: 15 req/sec

    > **utilization = TI (Queueing Delay 측정 지표) = La / R**

    


- avg data rate to browsers: 1.5Mbps (L*a) (req만큼 res도 15 req*100K bits)
- RTT from Internet router to any origin server: 2 sec
- access link rate: 1.54Mbps

utilization = TI = La/R

`conseuquences`

- LAN utilization: 15% (링크 사용률=1.5Mbps/10Mbps LAN)
- access link utilization: 99% (=TI=La/R=1.5Mbps/1.54Mbps) ← TI가 1에 가까울수록 problem!
- total delay = internet delay(origin servers to internet router) + access delay(output queue in internet router) + LAN delay(institutional router to origin clients)

### access link 증설


<img width="702" alt="스크린샷 2020-11-05 오후 4 12 08" src="https://user-images.githubusercontent.com/45806836/98209063-a8502900-1f81-11eb-9908-750355fbcf42.png">

access link utilization  = data rate to browsers/access link rate ⇒ 감소

but link  증설에 따른 cost 증가

### proxy 구축 (local cache)


<img width="706" alt="스크린샷 2020-11-05 오후 4 12 23" src="https://user-images.githubusercontent.com/45806836/98209097-b140fa80-1f81-11eb-9e70-ae07b191c3d7.png">


cache hit 40% → 초당 들어오는 15개의 request 중 40%가 internal traffic

cache miss 60% → 초당 들어오는 15개의 request 중 60%만 들어옴

⇒ avg response rate to browsers: 9 req/sec ⇒ a 가 감소

- avg data rate to browsers: 1.5Mbps*0.6 = 0.9Mbps
- LAN utilization: 15% (링크 사용률=0.9Mbps/10Mbps)
- access link utilization: 58% (=TI=0.9Mbps/1.54Mbps) ← enhanced!
- total delay = 0.6*(delay from origin servers) + 0.4*(delay when satisfied at cache = 0에 수렴)

    delay from origin servers = avg access delay + **avg internet delay**

## Conditional GET


<img width="701" alt="스크린샷 2020-11-05 오후 4 13 58" src="https://user-images.githubusercontent.com/45806836/98209226-eb120100-1f81-11eb-8e59-afd3ee4561e4.png">


Proxy Server가 Original Server의 Client가 됨.

`if-modified-since` 필드는 `last-modified` date 값을 가짐

- data 수정이 없는 경우

Proxy Server가 Server에게 Object 값이 수정되었는지 Conditional GET요청을 보냄. 바뀌지 않았다면 Object response 대신 `Not Modified` msg 전송

→ External traffic 없음

- data가 수정된 경우

200 OK로 Object를 response로 줌 → External traffic 생김

Proxy Server는 `last-modified` 필드의 date를 update

---

# 2.3 electronic mail

E-mail(loss-sensitive)을 support하는 application layer의 protocol 세 가지.

- SMTP : (sending/ delivering) 보내고 배달할 때 사용. Push protocol
- POP3, IMAP: receiving(accessing) 이메일을 받을 때 사용. Pull protocol

TCP connection initiate 시에 push(upload)/pull(download) protocol 정해짐

## Electronic mail

**Three major components**

- user agents (사용자 대신 인터넷에 접속하는 브라우저)
- mail servers (server와 server 사이는 SMTP protocol 사용)

→ user agent와 mail server는 동일 ISP 내에 있음(ex. ewhain mail, gmail)

- simple mail transfer protocol: SMTP (SMTP는 mail을 보낼 때만 사용)

→ user agent(client)가 동일 ISP의 mail server(server)에 send (by SMTP)

→ source의 user agent가 있는 ISP의 mail server(client)가 destination의 user agent가 있는 mail server(server)를 찾아 send (by SMTP)

⇒ 위의 SMTP는 모두 TCP connection 후 사용

## Electronic mail: mail servers

: mail을 보낼 땐 mail server에 push 해놓고, client별로 할당된 mailbox에서 client가 pull 해가는 구조

mail protocol은 sender mail server와 receiver mail server 간의 1:1 TCP connection을 맺음 (다른 server를 거치지 않음)

***mailbox*** incoming messages (user 별로 분류)

***message queue*** outgoing messages (ISP 별로 분류)

## Electronic mail: SMTP

- persistent TCP 사용 (loss-sensitive)
- direct transfer (다른 server를 거치지X sender에서 receiver server로)
- three phases of transfer (TCP)
    - handshaking (greeting)
    - transfer of messages
    - closure
- command/response interaction (like HTTP)
    - commands: 모두 7-bit ASCII text
    - response: status code and phrase

`Pop Quiz`

왜 sender의 user agent와 receiver의 mail server는 직접 연결을 맺지 않고 mail server를 통해 전달?

⇒ DNS resolution을 client가 한다면 mail server에 보관할 수 없음. 또한 user agent와 mail server 간에 연결이 되지 않는다면 계속 시도해야 함.

그래서 mail server가 대신 해주는 것

---

# Quiz

(46) HTTP pipelining이란 무엇인가? HTTP pipelining이 어떻게 가능한지 간략히 설명하시오.

⇒ HTTP pipelining이란 HTTP Request message가 응답을 기다리지 않고 single TCP connection으로 message를 이어 전송하는 것으로, TCP의 sliding window에 의해 server의 ACK 없이도 client의 sender buffer에서 server의 receiver buffer로 msgs가 한 번에 가게 된다.

(47) TCP를 사용하는 HTTP의 경우, HTTP 메시지를 전송하기 전에 양 끝 TCP들 사이에 전용소켓이 열리게 되고, 각 소켓을 식별하는 파라미터로 (상대방 TCP가 있는 호스트의 IP주소, 상대방 TCP가 서비스하고 있는 process의 포트번호)를 저장하고 있다. 그럼에도 불구하고, HTTP request 메시지에 Host: www-net.cs.umass.edu\r\n 즉, 상대방 TCP가 있는 호스트의 IP주소를 찾기 위한 URL을 포함하고있는 이유는 무엇인가?

⇒ Proxy Server가 존재한다면, Client가 ISP망 외부의 Server와 직접 연결을 맺지 않고, (대부분의 경우 동일 ISP망 내의) Proxy Server로 HTTP 메시지를 보낸다. Client가 요청하는 Object가 Proxy Server 내에 있을 경우 그대로 돌려주고, 없을 경우 Proxy Server에서 Original Server로 재요청을 하는데, 이 때 Server의 host url이 필요하기 때문에 HTTP request 메시지는 호스트의 url을 포함한다.

(48) 연습문제(자료게시판에서 다운로드) P5 (p3~4) 풀기 (오늘 수업시간에 설명한 access ISP 내부에 Web cache를 설비할 경우 access ISP 외부로 나가는 external access link의 트래픽이 감소함으로써 delay가 줄어드는 문제입니다. 오늘 꼭! 풀어보기 바랍니다.)


<img width="722" alt="스크린샷 2020-11-05 오후 4 14 45" src="https://user-images.githubusercontent.com/45806836/98209298-07ae3900-1f82-11eb-9150-d7ec88bd772d.png">


⇒ 

문제 해석 

avg Obj size = 900Kbits = L

avg Req/Res rate = 15/sec = a = B = ***arrival rate of the Obj to the access link***

amount of time it takes from when the router on the Internet side of the access link forwards an HTTP request until it receives the response = RTT

(a) total avg response time = avg access delay + avg Internet delay = 0.6s + 2s = 2.6s 

Δ = avg time to send an object over the access link = 900Kbits/15Mbps = 0.06s

β = arrival rate of objects to the access link = 15/sec

avg access delay = ∆/(1 − ∆β) = 0.06/0.1 = 0.6s

(b) total response time with cache hit rate is 0.4 = 0.6(2+0.13) = 2.178

β = arrival rate of objects to the access link = 9/sec

→ avg access delay = ∆/(1 − ∆β) = 0.06/0.46 = 0.13(둘째자리에서 반올림)

(49) A가 B에게 email을 보낸다고 가정하자. 이때 A의 user agent가 B의 메일서버에게 직접 TCP 연결을 맺고 SMTP 메시지를 보내지 않고, A가 속한 메일서버가 그 일을 대신한다. 그 이유 두가지를 적으시오.

⇒ 1. A의 user agent와 B의 메일서버와 직접 연결한다면, 만약 연결에 오류가 있을시 client가 계속 연결을 시도해야 한다.

2. A의 user agent와 B의 메일서버와 직접 연결한다면, 매번 client에서 DNS resolution을 해야 하지만, 두 메일 서버를 연결한다면 DNS를 재사용 할 수 있어 효율이 좋다.

(50) T/F를 표시하시오.

(a) 데이터를 업로드 하려는 목적으로 TCP 연결을 먼저 시도하는 프로토콜을 pull protocol 이라고 하고, 반대로, 데이터를 다운로드할 목적으로 TCP연결을 먼저 시도하는 프로토콜을 push protocol 이라고 한다.

⇒ F. 업로드용 프로토콜은 push, 다운로드용 프로토콜은 pull protocol이다.

(b) HTTP는 각 object별로 encoding이 가능하나, SMTP는 모든 object들이 동일하게 인코딩된다.

⇒ T.

(c) HTTP는 여러 object들을 하나의 메세지로 보낼 수 있으나, SMTP는 각 object들을 개별 메시지로 따로따로 보낸다.

⇒ F. HTTP는 각 Object를 개별 메시지로 요청하는데 반해 SMTP는 7-bit ASCII Text로 Encoding된 하나의 요청을 한다.
